# -*- coding: utf-8 -*-
"""Paper 4 - PhD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BtIg7anaYvpRj_HWC4Ts994JF-cNw_HD

# Initialization
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install shap
# threshold=0.5; weight_FTA=0.5; weight_criteria=0.5
# file_paths = [
#     # data simulation
#     '/content/drive/MyDrive/Paper 3/python_scripts/dataset.py',
# 
#     # functions and models
#     '/content/drive/MyDrive/Paper 3/python_scripts/functions.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/different_dl_models.py',
# 
#     # labeling
#     '/content/drive/MyDrive/Paper 3/python_scripts/fault tree.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/criteria and integration.py',
#     # '/content/drive/MyDrive/Paper 3/python_scripts/experiment with criteria threshold and FTA weights.py',
#     ]
# 
# for file_path in file_paths:
#     with open(file_path) as file:
#         exec(file.read())

df_p['p_ransomware_label']=round((weight_FTA*df_p['p_ransomware_FTA']+weight_criteria*df_p['p_ransomware_criteria']),3)
df_p['p_phishing_label']=round((weight_FTA*df_p['p_phishing_FTA']+weight_criteria*df_p['p_phishing_criteria']),3)
df_p['p_insider_label']=round((weight_FTA*df_p['p_insider_FTA']+weight_criteria*df_p['p_insider_criteria']),3)
df_p['p_data_label']=round((weight_FTA*df_p['p_data_FTA']+weight_criteria*df_p['p_data_criteria']),3)
df_p['p_supply_label']=round((weight_FTA*df_p['p_supply_FTA']+weight_criteria*df_p['p_supply_criteria']),3)

with open('/content/drive/MyDrive/Paper 3/python_scripts/labeling integration analysis.py') as file:
  exec(file.read())

"""# Base model experimentation"""

best_base_models=collections.defaultdict(list)
df_one_hot['p_ransomware_label']=round((weight_FTA*df_p['p_ransomware_FTA']+weight_criteria*df_p['p_ransomware_criteria']),3)
df_one_hot['p_phishing_label']=round((weight_FTA*df_p['p_phishing_FTA']+weight_criteria*df_p['p_phishing_criteria']),3)
df_one_hot['p_insider_label']=round((weight_FTA*df_p['p_insider_FTA']+weight_criteria*df_p['p_insider_criteria']),3)
df_one_hot['p_data_label']=round((weight_FTA*df_p['p_data_FTA']+weight_criteria*df_p['p_data_criteria']),3)
df_one_hot['p_supply_label']=round((weight_FTA*df_p['p_supply_FTA']+weight_criteria*df_p['p_supply_criteria']),3)

"""## Risk 1: Ransomware

Dataset
"""

label = 'p_ransomware_label'
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

"""### Model: deep learning"""

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
DL_models = [NeuralNetwork1(), NeuralNetwork2(), NeuralNetwork3(), NeuralNetwork4(), NeuralNetwork5(), NeuralNetwork6()]

DL_val_losses_list = []
DL_best_epochs = []
DL_min_val_losses = []

for i, model in enumerate(DL_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    DL_val_losses_list.append(val_losses)
    DL_best_epochs.append(best_epoch)
    DL_min_val_losses.append(min_val_loss)
best_base_models['risk_1'].extend(DL_models)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Placeholder to store metrics
metrics_dict = {}

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
for i, model in enumerate(DL_models):
    # Load best model state
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy().flatten()
    actual_values = test_y.numpy().flatten()

    # Compute metrics
    mse_model = mean_squared_error(actual_values, predictions_model)
    rmse_model = np.sqrt(mse_model)
    mae_model = mean_absolute_error(actual_values, predictions_model)
    r2_model = r2_score(actual_values, predictions_model)

    # Store metrics in the dictionary
    metrics_dict[f"DL_Model {i+1}"] = {
        'MSE': mse_model,
        'RMSE': rmse_model,
        'MAE': mae_model,
        'R²': r2_model
    }

# Print metrics for each model
for model_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

'''
# Set the color to an earth tone (shade of brown)
color = '#008080'

# Plot the test losses
plt.figure(figsize=(6, 3.5))
plt.plot(range(num_epochs), test_losses, color=color)
plt.scatter(best_epoch, min_test_loss, color='orange', label='Best Model')
plt.xlabel('Epoch')
plt.ylabel('Test Loss')
plt.title('Loss of DL Model')

plt.legend()
plt.show()
print("Best Epoch:", best_epoch)
print("Best Loss:", "{:.3e}".format(min_test_loss))
'''

"""### Model: linear regression

* Converting the dataset for linear regression
"""

# Convert to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
test_x_np = test_x.numpy()
test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

len(test_y_np)

"""* Start training"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/linear_models.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_1'].append(linear)
best_base_models['risk_1'].append(ridge_cv)
best_base_models['risk_1'].append(lasso_cv)

"""### Model: non-linear regression"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/non linear model.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_1'].append(non_linear_model)

# Convert numbers to desired formats
for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

# Create DataFrame
metrics_table = pd.DataFrame(metrics_dict)

# Specify the column order
column_order = ['DL_Model 1', 'DL_Model 2', 'DL_Model 3', 'DL_Model 4', 'DL_Model 5', 'DL_Model 6', 'Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression']

# Reorder the columns
metrics_table = metrics_table[column_order]

def highlight_values(data):
    attr = 'font-weight: bold'
    if data.name == 'R²':
        is_max = data == data.max()
        return [attr if v else '' for v in is_max]
    else:
        is_min = data == data.min()
        return [attr if v else '' for v in is_min]

total_table={'risk_1': metrics_table.copy()}
metrics_table.style.apply(highlight_values, axis=1)

"""## Risk 2: Phishing

Dataset
"""

label = 'p_phishing_label'
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

"""### Model: deep learning"""

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
DL_models = [NeuralNetwork1(), NeuralNetwork2(), NeuralNetwork3(), NeuralNetwork4(), NeuralNetwork5(), NeuralNetwork6()]
DL_val_losses_list = []
DL_best_epochs = []
DL_min_val_losses = []

for i, model in enumerate(DL_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    DL_val_losses_list.append(val_losses)
    DL_best_epochs.append(best_epoch)
    DL_min_val_losses.append(min_val_loss)

best_base_models['risk_2'].extend(DL_models)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Placeholder to store metrics
metrics_dict = {}

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
for i, model in enumerate(DL_models):
    # Load best model state
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy().flatten()
    actual_values = test_y.numpy().flatten()

    # Compute metrics
    mse_model = mean_squared_error(actual_values, predictions_model)
    rmse_model = np.sqrt(mse_model)
    mae_model = mean_absolute_error(actual_values, predictions_model)
    r2_model = r2_score(actual_values, predictions_model)

    # Store metrics in the dictionary
    metrics_dict[f"DL_Model {i+1}"] = {
        'MSE': mse_model,
        'RMSE': rmse_model,
        'MAE': mae_model,
        'R²': r2_model
    }

# Print metrics for each model
for model_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

'''
# Set the color to an earth tone (shade of brown)
color = '#008080'

# Plot the test losses
plt.figure(figsize=(6, 3.5))
plt.plot(range(num_epochs), test_losses, color=color)
plt.scatter(best_epoch, min_test_loss, color='orange', label='Best Model')
plt.xlabel('Epoch')
plt.ylabel('Test Loss')
plt.title('Loss of DL Model')

plt.legend()
plt.show()
print("Best Epoch:", best_epoch)
print("Best Loss:", "{:.3e}".format(min_test_loss))
'''

"""### Model: linear regression

* Converting the dataset for linear regression
"""

# Convert to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
test_x_np = test_x.numpy()
test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

"""* Start training"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/linear_models.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_2'].append(linear)
best_base_models['risk_2'].append(ridge_cv)
best_base_models['risk_2'].append(lasso_cv)

"""### Model: non-linear regression"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/non linear model.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_2'].append(non_linear_model)

# Convert numbers to desired formats
for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

# Create DataFrame
metrics_table = pd.DataFrame(metrics_dict)

# Specify the column order
column_order = ['DL_Model 1', 'DL_Model 2', 'DL_Model 3', 'DL_Model 4', 'DL_Model 5', 'DL_Model 6', 'Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression']

# Reorder the columns
metrics_table = metrics_table[column_order]
total_table['risk_2']=metrics_table.copy()
metrics_table.style.apply(highlight_values, axis=1)

"""## Risk 3: Insider Attack

Dataset
"""

label = 'p_insider_label'
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

"""### Model: deep learning"""

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
DL_models = [NeuralNetwork1(), NeuralNetwork2(), NeuralNetwork3(), NeuralNetwork4(), NeuralNetwork5(), NeuralNetwork6()]
DL_val_losses_list = []
DL_best_epochs = []
DL_min_val_losses = []

for i, model in enumerate(DL_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    DL_val_losses_list.append(val_losses)
    DL_best_epochs.append(best_epoch)
    DL_min_val_losses.append(min_val_loss)
best_base_models['risk_3'].extend(DL_models)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Placeholder to store metrics
metrics_dict = {}

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
for i, model in enumerate(DL_models):
    # Load best model state
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy().flatten()
    actual_values = test_y.numpy().flatten()

    # Compute metrics
    mse_model = mean_squared_error(actual_values, predictions_model)
    rmse_model = np.sqrt(mse_model)
    mae_model = mean_absolute_error(actual_values, predictions_model)
    r2_model = r2_score(actual_values, predictions_model)

    # Store metrics in the dictionary
    metrics_dict[f"DL_Model {i+1}"] = {
        'MSE': mse_model,
        'RMSE': rmse_model,
        'MAE': mae_model,
        'R²': r2_model
    }

# Print metrics for each model
for model_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

'''
# Set the color to an earth tone (shade of brown)
color = '#008080'

# Plot the test losses
plt.figure(figsize=(6, 3.5))
plt.plot(range(num_epochs), test_losses, color=color)
plt.scatter(best_epoch, min_test_loss, color='orange', label='Best Model')
plt.xlabel('Epoch')
plt.ylabel('Test Loss')
plt.title('Loss of DL Model')

plt.legend()
plt.show()
print("Best Epoch:", best_epoch)
print("Best Loss:", "{:.3e}".format(min_test_loss))
'''

"""### Model: linear regression

* Converting the dataset for linear regression
"""

# Convert to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
test_x_np = test_x.numpy()
test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

"""* Start training"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/linear_models.py'

with open(file_paths) as file:
    exec(file.read())
best_base_models['risk_3'].append(linear)
best_base_models['risk_3'].append(ridge_cv)
best_base_models['risk_3'].append(lasso_cv)

"""### Model: non-linear regression"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/non linear model.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_3'].append(non_linear_model)

# Convert numbers to desired formats
for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

# Create DataFrame
metrics_table = pd.DataFrame(metrics_dict)

# Specify the column order
column_order = ['DL_Model 1', 'DL_Model 2', 'DL_Model 3', 'DL_Model 4', 'DL_Model 5', 'DL_Model 6', 'Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression']

# Reorder the columns
metrics_table = metrics_table[column_order]
total_table['risk_3']=metrics_table.copy()

metrics_table.style.apply(highlight_values, axis=1)

"""## Risk 4: Data Breach

Dataset
"""

label = 'p_data_label'
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

"""### Model: deep learning"""

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
DL_models = [NeuralNetwork1(), NeuralNetwork2(), NeuralNetwork3(), NeuralNetwork4(), NeuralNetwork5(), NeuralNetwork6()]
DL_val_losses_list = []
DL_best_epochs = []
DL_min_val_losses = []

for i, model in enumerate(DL_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    DL_val_losses_list.append(val_losses)
    DL_best_epochs.append(best_epoch)
    DL_min_val_losses.append(min_val_loss)
best_base_models['risk_4'].extend(DL_models)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Placeholder to store metrics
metrics_dict = {}

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
for i, model in enumerate(DL_models):
    # Load best model state
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy().flatten()
    actual_values = test_y.numpy().flatten()

    # Compute metrics
    mse_model = mean_squared_error(actual_values, predictions_model)
    rmse_model = np.sqrt(mse_model)
    mae_model = mean_absolute_error(actual_values, predictions_model)
    r2_model = r2_score(actual_values, predictions_model)

    # Store metrics in the dictionary
    metrics_dict[f"DL_Model {i+1}"] = {
        'MSE': mse_model,
        'RMSE': rmse_model,
        'MAE': mae_model,
        'R²': r2_model
    }

# Print metrics for each model
for model_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

'''
# Set the color to an earth tone (shade of brown)
color = '#008080'

# Plot the test losses
plt.figure(figsize=(6, 3.5))
plt.plot(range(num_epochs), test_losses, color=color)
plt.scatter(best_epoch, min_test_loss, color='orange', label='Best Model')
plt.xlabel('Epoch')
plt.ylabel('Test Loss')
plt.title('Loss of DL Model')

plt.legend()
plt.show()
print("Best Epoch:", best_epoch)
print("Best Loss:", "{:.3e}".format(min_test_loss))
'''

"""### Model: linear regression

* Converting the dataset for linear regression
"""

# Convert to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
test_x_np = test_x.numpy()
test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

"""* Start training"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/linear_models.py'

with open(file_paths) as file:
    exec(file.read())

best_base_models['risk_4'].append(linear)
best_base_models['risk_4'].append(ridge_cv)
best_base_models['risk_4'].append(lasso_cv)

"""### Model: non-linear regression"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/non linear model.py'

with open(file_paths) as file:
    exec(file.read())
best_base_models['risk_4'].append(non_linear_model)

# Convert numbers to desired formats
for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

# Create DataFrame
metrics_table = pd.DataFrame(metrics_dict)

# Specify the column order
column_order = ['DL_Model 1', 'DL_Model 2', 'DL_Model 3', 'DL_Model 4', 'DL_Model 5', 'DL_Model 6', 'Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression']

# Reorder the columns
metrics_table = metrics_table[column_order]
total_table['risk_4']=metrics_table.copy()

metrics_table.style.apply(highlight_values, axis=1)

"""## Risk 5: Supply Chain Attack

Dataset
"""

label = 'p_supply_label'
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

"""### Model: deep learning"""

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
DL_models = [NeuralNetwork1(), NeuralNetwork2(), NeuralNetwork3(), NeuralNetwork4(), NeuralNetwork5(), NeuralNetwork6()]
DL_val_losses_list = []
DL_best_epochs = []
DL_min_val_losses = []

for i, model in enumerate(DL_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    DL_val_losses_list.append(val_losses)
    DL_best_epochs.append(best_epoch)
    DL_min_val_losses.append(min_val_loss)

best_base_models['risk_5'].extend(DL_models)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Placeholder to store metrics
metrics_dict = {}

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
for i, model in enumerate(DL_models):
    # Load best model state
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy().flatten()
    actual_values = test_y.numpy().flatten()

    # Compute metrics
    mse_model = mean_squared_error(actual_values, predictions_model)
    rmse_model = np.sqrt(mse_model)
    mae_model = mean_absolute_error(actual_values, predictions_model)
    r2_model = r2_score(actual_values, predictions_model)

    # Store metrics in the dictionary
    metrics_dict[f"DL_Model {i+1}"] = {
        'MSE': mse_model,
        'RMSE': rmse_model,
        'MAE': mae_model,
        'R²': r2_model
    }

# Print metrics for each model
for model_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

'''
# Set the color to an earth tone (shade of brown)
color = '#008080'

# Plot the test losses
plt.figure(figsize=(6, 3.5))
plt.plot(range(num_epochs), test_losses, color=color)
plt.scatter(best_epoch, min_test_loss, color='orange', label='Best Model')
plt.xlabel('Epoch')
plt.ylabel('Test Loss')
plt.title('Loss of DL Model')

plt.legend()
plt.show()
print("Best Epoch:", best_epoch)
print("Best Loss:", "{:.3e}".format(min_test_loss))
'''

"""### Model: linear regression

* Converting the dataset for linear regression
"""

# Convert to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
test_x_np = test_x.numpy()
test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

"""* Start training"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/linear_models.py'

with open(file_paths) as file:
    exec(file.read())
best_base_models['risk_5'].append(linear)
best_base_models['risk_5'].append(ridge_cv)
best_base_models['risk_5'].append(lasso_cv)

"""### Model: non-linear regression"""

file_paths = '/content/drive/MyDrive/Paper 3/python_scripts/non linear model.py'

with open(file_paths) as file:
    exec(file.read())
best_base_models['risk_5'].append(non_linear_model)

# Convert numbers to desired formats
for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

# Create DataFrame
metrics_table = pd.DataFrame(metrics_dict)

# Specify the column order
column_order = ['DL_Model 1', 'DL_Model 2', 'DL_Model 3', 'DL_Model 4', 'DL_Model 5', 'DL_Model 6', 'Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression']

# Reorder the columns
metrics_table = metrics_table[column_order]
total_table['risk_5']=metrics_table.copy()

metrics_table.style.apply(highlight_values, axis=1)

"""## Combined model"""

# dataset
set_seed(0)
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :-5].values)
train_y = torch.Tensor(train_df.iloc[:, -5:].values)
val_x = torch.Tensor(val_df.iloc[:, :-5].values)
val_y = torch.Tensor(val_df.iloc[:, -5:].values)
test_x = torch.Tensor(test_df.iloc[:, :-5].values)
test_y = torch.Tensor(test_df.iloc[:, -5:].values)

set_seed(0)

num_epochs = 200
lr = 0.004

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

criterion = nn.MSELoss()
combined_models = [Combined1(), Combined2(), Combined3()]  # Reduced to 3 models that we have defined
combined_val_losses_list = []
combined_best_epochs = []
combined_min_val_losses = []

for i, model in enumerate(combined_models):
    print(f"Training Model {i+1}...")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_combined_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)
    combined_val_losses_list.append(val_losses)
    combined_best_epochs.append(best_epoch)
    combined_min_val_losses.append(min_val_loss)

for i in range(1,6):
  best_base_models[f'risk_{i}'].extend(combined_models)

# For each model, load the best model, set it to evaluation mode, generate predictions, and compute metrics
metrics_dict={}
for i, model in enumerate(combined_models):  # Use your combined models
    model.eval()

    with torch.no_grad():
        # Generate predictions
        predictions_model = model(test_x.to(device))

    # Convert the predictions and actual values to numpy arrays
    predictions_model = predictions_model.cpu().numpy()
    actual_values = test_y.numpy()

    # Compute metrics for each label
    for label_index in range(predictions_model.shape[1]):
        # Extract predictions and actual values for this label
        predictions_label = predictions_model[:, label_index]
        actual_values_label = actual_values[:, label_index]

        # Compute metrics
        mse_model = mean_squared_error(actual_values_label, predictions_label)
        rmse_model = np.sqrt(mse_model)
        mae_model = mean_absolute_error(actual_values_label, predictions_label)
        r2_model = r2_score(actual_values_label, predictions_label)

        # Store metrics in the dictionary
        metrics_dict[f"Combined_Model {i+1}_Risk {label_index+1}"] = {
            'MSE': mse_model,
            'RMSE': rmse_model,
            'MAE': mae_model,
            'R²': r2_model
        }

# Print metrics for each model and each label
for model_label_name, model_metrics in metrics_dict.items():
    print(f"Metrics for {model_label_name}:")
    print(f"Mean Squared Error (MSE): {model_metrics['MSE']:.3e}")
    print(f"Root Mean Squared Error (RMSE): {model_metrics['RMSE']:.3e}")
    print(f"Mean Absolute Error (MAE): {model_metrics['MAE']:.3e}")
    print(f"R-squared (R²): {round(model_metrics['R²'],3)}\n")

for model, metrics in metrics_dict.items():
    for metric, value in metrics.items():
        if metric in ['MSE', 'RMSE', 'MAE']:
            metrics_dict[model][metric] = "{:.3e}".format(value)
        elif metric == 'R²':
            metrics_dict[model][metric] = "{:.3f}".format(value)

total_table

for i in range(1,6):
  for j in range(1,4):
    total_table[f'risk_{i}'][f'Combined_Model_{j}']=metrics_dict[f"Combined_Model {j}_Risk {i}"]

best_values_dict = {}

for key in total_table.keys():
    # Get current dataframe
    df = total_table[key]

    # Create a new dataframe to store the best values
    best_values_df = pd.DataFrame(False, index=df.index, columns=df.columns)

    # For 'MSE', 'RMSE', and 'MAE', set True for the min values
    for metric in ['MSE', 'RMSE', 'MAE']:
        min_value = df.loc[metric].min()
        best_values_df.loc[metric] = df.loc[metric].apply(lambda x: x == min_value)

    # For 'R²', set True for the max values
    max_value = df.loc['R²'].max()
    best_values_df.loc['R²'] = df.loc['R²'].apply(lambda x: x == max_value)

    # Store the dataframe of best values in the new dictionary
    best_values_dict[key] = best_values_df


# Now you can concat the dataframes as before
combined_df = pd.concat(total_table.values(), keys=total_table.keys())
combined_best_values_df=pd.concat(best_values_dict.values(), keys=best_values_dict.keys())
combined_df
# combined_best_values_df

import numpy as np

# Initialize an empty dictionary to store the results
results_original = {}

# Iterate over each risk and metric to compute mean, variance, and best performance
for risk in [f'risk_{i+1}' for i in range(5)]:
    results_original[risk] = {}
    for metric in ['MSE', 'RMSE', 'MAE', 'R²']:
        metric_values = {model: float(combined_df[model][risk][metric]) for model in combined_df}

        # Check and format the mean value based on the metric
        mean_value_list = list(metric_values.values())
        if metric != 'R²':
            mean_value = "{:.2e}".format(np.mean(mean_value_list))
        else:
            mean_value = round(np.mean(mean_value_list), 3)

        # Check and format the variance value based on the metric
        if metric != 'R²':
            variance_value = "{:.2e}".format(np.var(mean_value_list))
        else:
            variance_value = round(np.var(mean_value_list), 3)

        # Determine the best performance based on the metric
        if metric in ['MSE', 'RMSE', 'MAE']:
            best_performance = min(metric_values.values())
            best_models = [model for model, value in metric_values.items() if value == best_performance]
        else:  # For R²
            best_performance = max(metric_values.values())
            best_models = [model for model, value in metric_values.items() if value == best_performance]

        if metric != 'R²':
            best_formatted = "{:.2e}".format(best_performance)
        else:
            best_formatted = round(best_performance, 3)

        results_original[risk][metric] = {
            'mean': mean_value,
            'variance': variance_value,
            'best_performance': best_formatted,
            'best_models': best_models  # This is now a list of models
        }

results_original

# Flatten the nested dictionary structure into a list of rows
rows = []
for risk, metrics in results_original.items():
    for metric, values in metrics.items():
        row = {
            'Risk': risk,
            'Metric': metric,
            'Mean': values['mean'],
            'Variance': values['variance'],
            'Best Performance': values['best_performance'],
            'Best Models': ", ".join(values['best_models'])
        }
        rows.append(row)

# Create a DataFrame from the list of rows
df_overview = pd.DataFrame(rows)

# Sort and reorder columns for better display
df_overview = df_overview[['Risk', 'Metric', 'Mean', 'Variance', 'Best Performance', 'Best Models']]

# Display the table
df_overview

combined_df.to_csv('metrics.csv', index=True)
combined_best_values_df.to_csv('boolean.csv', index=True)

"""# Sensitivity analysis
* I need to change the model
* I need to change the label
* I need to change the output index if it is combined model

For reloading the dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install shap
# threshold=0.5
# file_paths = [
#     # data simulation
#     '/content/drive/MyDrive/Paper 3/python_scripts/dataset.py',
# 
#     # functions and models
#     '/content/drive/MyDrive/Paper 3/python_scripts/functions.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/different_dl_models.py',
# 
#     # labeling
#     '/content/drive/MyDrive/Paper 3/python_scripts/fault tree.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/criteria and integration.py',
#     #'/content/drive/MyDrive/Paper 3/python_scripts/labeling integration analysis.py',
#     # '/content/drive/MyDrive/Paper 3/python_scripts/experiment with criteria threshold and FTA weights.py',
#     ]
# 
# for file_path in file_paths:
#     with open(file_path) as file:
#         exec(file.read())

"""For transforming the ALEC data to required format"""

new_sample_values = [0, 4, 2, 4, 5, 3, 1, 1, 2, 4, 5, 5, 5, 5, 5, 5, 1, 3, 7, 7, 7, 7, 7, 7, 0, 4, 2, 0, 4, 4, 1, 2, 2, 1, 5, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1]
simulated_one = [2, 2, 3, 2, 2, 3, 1, 4, 2, 1, 3, 0, 0, 0, 0, 5, 3, 3, 5, 0, 1, 1, 1, 6, 2, 1, 2, 1, 2, 2, 3, 1, 1, 2, 2, 2, 3, 1, 2, 3, 2, 0, 0, 1, 1, 2]
simulated_two = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 0, 0, 0, 1, 0, 3, 1, 7, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
df_copy = df.copy()

# Convert your simulated data into pandas series
new_sample = pd.Series(new_sample_values, index=df_copy.columns)
simulated_one_series = pd.Series(simulated_one, index=df_copy.columns)
simulated_two_series = pd.Series(simulated_two, index=df_copy.columns)

# Append these series to the dataframe
df_copy = df_copy.append(new_sample, ignore_index=True)
df_copy = df_copy.append(simulated_one_series, ignore_index=True)
df_copy = df_copy.append(simulated_two_series, ignore_index=True)

# Perform the same one-hot encoding
df_str_copy = df_copy.astype(str)
df_one_hot_copy = pd.get_dummies(df_str_copy)

# Now you can add these new samples to your test tensor
samples_df = df_one_hot_copy.iloc[len(df_copy)-3:]
test_sample_tensors = [torch.tensor(row.astype(int), dtype=torch.float) for _, row in samples_df.iterrows()]

"""## For the best model: DL model"""

risks = ['ransomware', 'phishing']
weights = np.linspace(0, 1, 11)  # create an array from 0 to 1 with 11 points (0, 0.1, 0.2, ..., 1)

results = {}

for risk in risks:
    predictions_sample_1 = []
    predictions_sample_2 = []
    predictions_sample_3 = []

    for weight in weights:
        weight = round(weight, 1)  # rounding to 2 decimal places
        inverse_weight = round(1 - weight, 1)

        df_one_hot[f'p_{risk}_label'] = round((weight * df_p[f'p_{risk}_FTA'] + inverse_weight * df_p[f'p_{risk}_criteria']), 3)

        set_seed(0)
        label = f'p_{risk}_label'

        train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
        train_x = torch.Tensor(train_df.iloc[:, :259].values)
        train_y = torch.Tensor(train_df[label].values).view(-1, 1)
        val_x = torch.Tensor(val_df.iloc[:, :259].values)
        val_y = torch.Tensor(val_df[label].values).view(-1, 1)
        test_x = torch.Tensor(test_df.iloc[:, :259].values)
        test_y = torch.Tensor(test_df[label].values).view(-1, 1)

        train_dataset = TensorDataset(train_x, train_y)
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_dataset = TensorDataset(val_x, val_y)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        test_dataset = TensorDataset(test_x, test_y)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

        model = NeuralNetwork2()
        num_epochs = 200
        lr = 0.004
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)
        model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)

        model.eval()
        with torch.no_grad():
            for i, test_sample in enumerate(test_sample_tensors):
                prediction = model(test_sample.to(device))
                if i == 0:
                    predictions_sample_1.append(round(prediction.item(), 2))
                elif i == 1:
                    predictions_sample_2.append(round(prediction.item(), 2))
                else:
                    predictions_sample_3.append(round(prediction.item(), 2))

    # Construct a DataFrame for the current risk and store it in the results dictionary
    predictions_df = pd.DataFrame({
        'Weight Pair': [(round(weight, 1), round(1 - weight, 1)) for weight in weights],
        'Sample 1 Predictions': predictions_sample_1,
        'Sample 2 Predictions': predictions_sample_2,
        'Sample 3 Predictions': predictions_sample_3
    })

    results[risk] = predictions_df

# Convert the results dictionary to a multi-indexed dataframe
df_dl = pd.concat(results, names=['Risk', 'Row Index'])
df_dl

risk='ransomware'
weight = 0.5; inverse_weight = 0.5
df_one_hot[f'p_{risk}_label'] = round((weight * df_p[f'p_{risk}_FTA'] + inverse_weight * df_p[f'p_{risk}_criteria']), 3)
set_seed(0)

label = f'p_{risk}_label'
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)
val_x = torch.Tensor(val_df.iloc[:, :259].values)
val_y = torch.Tensor(val_df[label].values).view(-1, 1)
test_x = torch.Tensor(test_df.iloc[:, :259].values)
test_y = torch.Tensor(test_df[label].values).view(-1, 1)

train_dataset = TensorDataset(train_x, train_y)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataset = TensorDataset(val_x, val_y)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_dataset = TensorDataset(test_x, test_y)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

model = NeuralNetwork2()
num_epochs = 200
lr = 0.004
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=lr)
model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)

import matplotlib.pyplot as plt

# Find the index (epoch) and value of the minimum loss
min_index = val_losses.index(min(val_losses))
min_value = min(val_losses)

# Morandi-inspired color (soft muted green)
morandi_color = '#A7B2A1'  # Example of a soft, muted green

# Plotting the validation losses
plt.plot(val_losses, label='Validation Loss', color=morandi_color)
plt.scatter(min_index, min_value, color='black', label='Lowest Loss', zorder=3)

# Annotating only the epoch of the lowest loss
plt.text(min_index, min_value, f'Epoch {min_index}', fontsize=10, ha='right', va='bottom')

plt.xlabel('Epoch')
plt.ylabel('Validation Loss')
plt.title('Validation Loss Over Epochs for Ransomware')
plt.legend()
plt.show()

"""## For the best model: combined"""

risks = ['data']
weights = np.linspace(0, 1, 11)  # create an array from 0 to 1 with 11 points (0, 0.1, 0.2, ..., 1)

risk_index_map = {
    'ransomware': 0,
    'phishing': 1,
    'insider': 2,
    'data': 3,
    'supply': 4
}

results = {}

for risk in risks:
    predictions_sample_1 = []
    predictions_sample_2 = []
    predictions_sample_3 = []

    for weight in weights:
        weight = round(weight, 1)  # rounding to 2 decimal places
        inverse_weight = round(1 - weight, 1)

        df_one_hot['p_ransomware_label']=round((weight*df_p['p_ransomware_FTA']+inverse_weight*df_p['p_ransomware_criteria']),3)
        df_one_hot['p_phishing_label']=round((weight*df_p['p_phishing_FTA']+inverse_weight*df_p['p_phishing_criteria']),3)
        df_one_hot['p_insider_label']=round((weight*df_p['p_insider_FTA']+inverse_weight*df_p['p_insider_criteria']),3)
        df_one_hot['p_data_label']=round((weight*df_p['p_data_FTA']+inverse_weight*df_p['p_data_criteria']),3)
        df_one_hot['p_supply_label']=round((weight*df_p['p_supply_FTA']+inverse_weight*df_p['p_supply_criteria']),3)

        set_seed(0)
        label = f'p_{risk}_label'

        train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
        train_x = torch.Tensor(train_df.iloc[:, :-5].values)
        train_y = torch.Tensor(train_df.iloc[:, -5:].values)
        val_x = torch.Tensor(val_df.iloc[:, :-5].values)
        val_y = torch.Tensor(val_df.iloc[:, -5:].values)
        test_x = torch.Tensor(test_df.iloc[:, :-5].values)
        test_y = torch.Tensor(test_df.iloc[:, -5:].values)

        train_dataset = TensorDataset(train_x, train_y)
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_dataset = TensorDataset(val_x, val_y)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        test_dataset = TensorDataset(test_x, test_y)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

        model = Combined3()
        num_epochs = 200
        lr = 0.004
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)
        model, val_losses, best_epoch, min_val_loss = train_combined_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)

        model.eval()
        prediction_index = risk_index_map[risk]
        with torch.no_grad():
            for i, test_sample in enumerate(test_sample_tensors):
                prediction = model(test_sample.to(device))[prediction_index]
                if i == 0:
                    predictions_sample_1.append(round(prediction.item(), 2))
                elif i == 1:
                    predictions_sample_2.append(round(prediction.item(), 2))
                else:
                    predictions_sample_3.append(round(prediction.item(), 2))

    # Construct a DataFrame for the current risk and store it in the results dictionary
    predictions_df = pd.DataFrame({
        'Weight Pair': [(round(weight, 1), round(1 - weight, 1)) for weight in weights],
        'Sample 1 Predictions': predictions_sample_1,
        'Sample 2 Predictions': predictions_sample_2,
        'Sample 3 Predictions': predictions_sample_3
    })

    results[risk] = predictions_df

# Convert the results dictionary to a multi-indexed dataframe
df_combined = pd.concat(results, names=['Risk', 'Row Index'])
# Display the combined dataframe
df_combined

"""## For the best model: ridge regression"""

risks = ['insider', 'supply']
weights = np.linspace(0, 1, 11)  # create an array from 0 to 1 with 11 points (0, 0.1, 0.2, ..., 1)

from sklearn.linear_model import Ridge
# List of risks to iterate over
risk_results = {}

for risk in risks:
    print(f"Processing {risk}...")

    # Initialize lists to hold predictions for each sample for the current risk
    predictions_sample_1 = []
    predictions_sample_2 = []
    predictions_sample_3 = []

    for weight in weights:
        weight = round(weight, 1)  # rounding to 2 decimal places
        inverse_weight = round(1 - weight, 1)

        df_one_hot[f'p_{risk}_label'] = round((weight * df_p[f'p_{risk}_FTA'] + inverse_weight * df_p[f'p_{risk}_criteria']), 3)

        set_seed(0)
        label = f'p_{risk}_label'

        train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])

        train_x = torch.Tensor(train_df.iloc[:, :259].values)
        train_y = torch.Tensor(train_df[label].values).view(-1, 1)
        val_x = torch.Tensor(val_df.iloc[:, :259].values)
        val_y = torch.Tensor(val_df[label].values).view(-1, 1)
        test_x = torch.Tensor(test_df.iloc[:, :259].values)
        test_y = torch.Tensor(test_df[label].values).view(-1, 1)

        train_val_x_np = train_x.numpy()
        train_val_y_np = train_y.numpy().reshape(-1,)

        test_x_np = test_x.numpy()
        test_y_np = test_y.numpy().reshape(-1,)

        ridge = Ridge()

        param_grid = {'alpha': np.logspace(-4, 4, 100)}
        ridge_cv = GridSearchCV(ridge, param_grid, cv=5)
        ridge_cv.fit(train_val_x_np, train_val_y_np)

        print("Best alpha: ", ridge_cv.best_params_)

        for i, test_sample in enumerate(test_sample_tensors):
            ridge_pred = ridge_cv.predict(test_sample.view(1, -1).numpy())

            if i == 0:
                predictions_sample_1.append(round(ridge_pred[0], 2))
            elif i == 1:
                predictions_sample_2.append(round(ridge_pred[0], 2))
            else:
                predictions_sample_3.append(round(ridge_pred[0], 2))

    predictions_df = pd.DataFrame({
        'Weight Pair': [(round(weight, 1), round(1 - weight, 1)) for weight in weights],
        'Sample 1 Predictions': predictions_sample_1,
        'Sample 2 Predictions': predictions_sample_2,
        'Sample 3 Predictions': predictions_sample_3
    })

    risk_results[risk] = predictions_df

# Convert the results dictionary to a multi-indexed dataframe
df_regression = pd.concat(risk_results, names=['Risk', 'Row Index'])
# Display the combined dataframe
df_regression

df_combined

samples = ['Sample 1 Predictions', 'Sample 2 Predictions', 'Sample 3 Predictions']
risks_order = ['ransomware', 'phishing', 'insider', 'data', 'supply']

# Concatenate the results from deep learning, combined model, and regression model
final_df = pd.concat([df_dl, df_combined, df_regression], axis=0)

# Pivot the final dataframe to reshape it
reshaped_df = final_df.pivot_table(index='Weight Pair', columns=['Risk'], values=samples, aggfunc='first')

# Define the desired multi-level column order
column_order = pd.MultiIndex.from_product([samples, risks_order])

# Reorder the columns of the reshaped dataframe according to the defined order
reshaped_df = reshaped_df[column_order]

reshaped_df

"""# Feature importance

## Feature importance of linear regression for 5 risks
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install shap
# threshold=0.5; weight_FTA=0.6; weight_criteria=0.4
# file_paths = [
#     # data simulation
#     '/content/drive/MyDrive/Paper 3/python_scripts/dataset.py',
# 
#     # functions and models
#     '/content/drive/MyDrive/Paper 3/python_scripts/functions.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/different_dl_models.py',
# 
#     # labeling
#     '/content/drive/MyDrive/Paper 3/python_scripts/fault tree.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/criteria and integration.py',
#     #'/content/drive/MyDrive/Paper 3/python_scripts/labeling integration analysis.py',
#     # '/content/drive/MyDrive/Paper 3/python_scripts/experiment with criteria threshold and FTA weights.py',
#     ]
# 
# for file_path in file_paths:
#     with open(file_path) as file:
#         exec(file.read())
# features = df_one_hot.columns[:259]
# 
# dfs = []
# df_one_hot['p_ransomware_label']=round((weight_FTA*df_p['p_ransomware_FTA']+weight_criteria*df_p['p_ransomware_criteria']),3)
# df_one_hot['p_phishing_label']=round((weight_FTA*df_p['p_phishing_FTA']+weight_criteria*df_p['p_phishing_criteria']),3)
# df_one_hot['p_insider_label']=round((weight_FTA*df_p['p_insider_FTA']+weight_criteria*df_p['p_insider_criteria']),3)
# df_one_hot['p_data_label']=round((weight_FTA*df_p['p_data_FTA']+weight_criteria*df_p['p_data_criteria']),3)
# df_one_hot['p_supply_label']=round((weight_FTA*df_p['p_supply_FTA']+weight_criteria*df_p['p_supply_criteria']),3)

"""* For linear regression"""

def compute_shap_importance_linear(model, train_x, test_x, features):
    explainer = shap.Explainer(model.predict, train_x)
    shap_values = explainer(test_x, max_evals=520).values
    mean_shap_values = np.abs(shap_values).mean(axis=0)
    original_feature_shap = {}
    original_feature_count = {}

    for feature, shap_value in zip(features, mean_shap_values):
        original_feature = feature[:-2]
        if original_feature not in original_feature_shap:
            original_feature_shap[original_feature] = shap_value
            original_feature_count[original_feature] = 1
        else:
            original_feature_shap[original_feature] += shap_value
            original_feature_count[original_feature] += 1

    # compute the average SHAP values
    average_shap_values = {k: v/original_feature_count[k] for k, v in original_feature_shap.items()}

    # normalize the average SHAP values
    total_shap = sum(average_shap_values.values())
    normalized_shap_values = {k: v/total_shap for k, v in average_shap_values.items()}

    sorted_average_shap_values = sorted(normalized_shap_values.items(), key=lambda item: (item[1], item[0]), reverse=True)
    return sorted_average_shap_values

dfs = []

for risk in ['ransomware', 'phishing', 'insider', 'data', 'supply']:
    label = f'p_{risk}_label'
    set_seed(0)

    # Split the dataset into training, validation and testing datasets
    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])

    # Get the features and labels for each dataset
    train_x = torch.Tensor(train_df.iloc[:, :259].values)
    train_y = torch.Tensor(train_df[label].values).view(-1, 1)
    val_x = torch.Tensor(val_df.iloc[:, :259].values)
    val_y = torch.Tensor(val_df[label].values).view(-1, 1)
    test_x = torch.Tensor(test_df.iloc[:, :259].values)
    test_y = torch.Tensor(test_df[label].values).view(-1, 1)

    # Convert to numpy arrays for scikit-learn
    train_x_np = train_x.numpy()
    train_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
    val_x_np = val_x.numpy()
    val_y_np = val_y.numpy().reshape(-1,)  # Reshape to 1D if needed
    test_x_np = test_x.numpy()
    test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

    linear = LinearRegression()
    linear.fit(train_x_np, train_y_np)

    # Now compute the sorted average SHAP values
    sorted_average_shap_values = compute_shap_importance_linear(linear, train_x_np, test_x_np, features)

    # Create a DataFrame for this risk and append to dfs list
    risk_df = pd.DataFrame(sorted_average_shap_values[:10], columns=['Feature', 'Average SHAP Value'])
    risk_df['Risk'] = risk  # Add a column for the risk type

    # Reorder the columns to: Risk, Feature, Average SHAP Value
    risk_df = risk_df[['Risk', 'Feature', 'Average SHAP Value']]
    risk_df['Average SHAP Value'] = risk_df['Average SHAP Value'].round(4)  # Round to four decimal places

    dfs.append(risk_df)

# After the loop, concatenate the list of DataFrames
all_results_df_linear = pd.concat(dfs, ignore_index=True)
all_results_df_linear

"""## Best model: DL"""

def compute_shap_importance(model, train_x, test_x, features):
    explainer = shap.DeepExplainer(model, train_x.to(device))
    shap_values = explainer.shap_values(test_x)
    mean_shap_values = np.abs(shap_values).mean(axis=0)
    original_feature_shap = {}
    original_feature_count = {}

    for feature, shap_value in zip(features, mean_shap_values):
        original_feature = feature[:-2]
        if original_feature not in original_feature_shap:
            original_feature_shap[original_feature] = shap_value
            original_feature_count[original_feature] = 1
        else:
            original_feature_shap[original_feature] += shap_value
            original_feature_count[original_feature] += 1

    # compute the average SHAP values
    average_shap_values = {k: v/original_feature_count[k] for k, v in original_feature_shap.items()}

    # normalize the average SHAP values
    total_shap = sum(average_shap_values.values())
    normalized_shap_values = {k: v/total_shap for k, v in average_shap_values.items()}

    sorted_average_shap_values = sorted(normalized_shap_values.items(), key=lambda item: (item[1], item[0]), reverse=True)
    return sorted_average_shap_values

dfs = []

for risk in ['ransomware', 'phishing']:
    set_seed(0)
    label = f'p_{risk}_label'

    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :259].values)
    train_y = torch.Tensor(train_df[label].values).view(-1, 1)
    val_x = torch.Tensor(val_df.iloc[:, :259].values)
    val_y = torch.Tensor(val_df[label].values).view(-1, 1)
    test_x = torch.Tensor(test_df.iloc[:, :259].values)
    test_y = torch.Tensor(test_df[label].values).view(-1, 1)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    criterion = nn.MSELoss()
    model = NeuralNetwork2()
    num_epochs = 200
    lr = 0.004
    optimizer = optim.Adam(model.parameters())
    criterion = nn.MSELoss()
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)
    features = df_one_hot.columns[:259]
    sns.set_style('ticks')

    # Compute shap_values for the summary plot
    # explainer = shap.DeepExplainer(model, train_x.to(device))
    # shap_values = explainer.shap_values(train_x)
    # shap.summary_plot(shap_values, train_x, feature_names=features, max_display=10, show=False)

    # Now compute the sorted average SHAP values
    sorted_average_shap_values = compute_shap_importance(model, train_x, test_x, features)

    # Create a DataFrame for this risk and append to dfs list
    risk_df = pd.DataFrame(sorted_average_shap_values[:10], columns=['Feature', 'Average SHAP Value'])
    risk_df['Risk'] = risk  # Add a column for the risk type

    # Reorder the columns to: Risk, Feature, Average SHAP Value
    risk_df = risk_df[['Risk', 'Feature', 'Average SHAP Value']]
    risk_df['Average SHAP Value'] = risk_df['Average SHAP Value'].apply(lambda x: x[0]).round(4)  # Round to four decimal places

    dfs.append(risk_df)

# After the loop, concatenate the list of DataFrames
all_results_df_DL = pd.concat(dfs, ignore_index=True)
all_results_df_DL

"""## Best model: combined"""

dfs = []

for risk in ['data']:

    label = f'p_{risk}_label'
    set_seed(0)
    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :-5].values)
    train_y = torch.Tensor(train_df.iloc[:, -5:].values)
    val_x = torch.Tensor(val_df.iloc[:, :-5].values)
    val_y = torch.Tensor(val_df.iloc[:, -5:].values)
    test_x = torch.Tensor(test_df.iloc[:, :-5].values)
    test_y = torch.Tensor(test_df.iloc[:, -5:].values)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    num_epochs = 200
    lr = 0.004
    criterion = nn.MSELoss()
    model=Combined3()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_combined_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)

    explainer = shap.DeepExplainer(model, train_x.to(device))
    shap_values = explainer.shap_values(test_x)
    if risk=='ransomware': index=0
    elif risk=='phishing': index=1
    elif risk=='insider': index=2
    elif risk=='data': index=3
    else: index=4
    shap_values_2nd_output = shap_values[:,:,index] # get the shap values of the 2nd output
    mean_shap_values = np.abs(shap_values_2nd_output).mean(axis=0)
    features=df_one_hot.columns[:-5]
    sns.set_style('ticks')
    # shap.summary_plot(shap_values_2nd_output, test_x, feature_names=features, max_display=10, show=False)

    # dictionary to store the summed shap values and count of each original feature
    original_feature_shap = {}
    original_feature_count = {}

    # go through each feature and its corresponding mean shap value
    for feature, shap_value in zip(features, mean_shap_values):
        # the original feature name is the part before the underscore in the one-hot encoded feature name
        # and taking only the first three characters to group sub-features
        original_feature = feature[:-2]

        # if this original feature hasn't been seen before, add it to the dictionary with its shap value
        if original_feature not in original_feature_shap:
            original_feature_shap[original_feature] = abs(shap_value)
            original_feature_count[original_feature] = 1
        # if this original feature has been seen before, add the shap value to the current sum
        else:
            original_feature_shap[original_feature] += abs(shap_value)
            original_feature_count[original_feature] += 1

    # compute the average shap values
    average_shap_values = {k: v/original_feature_count[k] for k, v in original_feature_shap.items()}
    # normalize the average SHAP values
    total_shap = sum(average_shap_values.values())
    normalized_shap_values = {k: v/total_shap for k, v in average_shap_values.items()}

    # sort by average shap value
    sorted_average_shap_values = sorted(normalized_shap_values.items(), key=lambda item: (item[1],item[0]), reverse=True)

    data = [[risk, feature, round(shap_value, 4)] for feature, shap_value in sorted_average_shap_values[:10]]
    risk_df = pd.DataFrame(data, columns=['Risk', 'Feature', 'Average SHAP Value'])
    dfs.append(risk_df)
all_results_df_combined = pd.concat(dfs, ignore_index=True)
all_results_df_combined

"""## Best model: regression"""

def compute_shap_importance_ridge(model, train_x, test_x, features):
    explainer = shap.Explainer(model.predict, train_x)
    shap_values = explainer(test_x, max_evals=520).values
    mean_shap_values = np.abs(shap_values).mean(axis=0)
    original_feature_shap = {}
    original_feature_count = {}

    for feature, shap_value in zip(features, mean_shap_values):
        original_feature = feature[:-2]
        if original_feature not in original_feature_shap:
            original_feature_shap[original_feature] = shap_value
            original_feature_count[original_feature] = 1
        else:
            original_feature_shap[original_feature] += shap_value
            original_feature_count[original_feature] += 1

    # compute the average SHAP values
    average_shap_values = {k: v/original_feature_count[k] for k, v in original_feature_shap.items()}

    # normalize the average SHAP values
    total_shap = sum(average_shap_values.values())
    normalized_shap_values = {k: v/total_shap for k, v in average_shap_values.items()}

    sorted_average_shap_values = sorted(normalized_shap_values.items(), key=lambda item: (item[1], item[0]), reverse=True)
    return sorted_average_shap_values

dfs = []

for risk in ['insider', 'supply']:
    label = f'p_{risk}_label'
    set_seed(0)

    # Split the dataset into training, validation and testing datasets
    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])

    # Get the features and labels for each dataset
    train_x = torch.Tensor(train_df.iloc[:, :259].values)
    train_y = torch.Tensor(train_df[label].values).view(-1, 1)
    val_x = torch.Tensor(val_df.iloc[:, :259].values)
    val_y = torch.Tensor(val_df[label].values).view(-1, 1)
    test_x = torch.Tensor(test_df.iloc[:, :259].values)
    test_y = torch.Tensor(test_df[label].values).view(-1, 1)

    # Convert to numpy arrays for scikit-learn
    train_x_np = train_x.numpy()
    train_y_np = train_y.numpy().reshape(-1,)  # Reshape to 1D if needed
    val_x_np = val_x.numpy()
    val_y_np = val_y.numpy().reshape(-1,)  # Reshape to 1D if needed
    test_x_np = test_x.numpy()
    test_y_np = test_y.numpy().reshape(-1,)  # Reshape to 1D if needed

    ridge = Ridge()
    # Grid search parameters
    param_grid = {'alpha': np.logspace(-4, 4, 100)}
    # Ridge regression with grid search
    ridge_cv = GridSearchCV(ridge, param_grid, cv=5)
    ridge_cv.fit(train_x_np, train_y_np)

    # Now compute the sorted average SHAP values
    sorted_average_shap_values = compute_shap_importance_ridge(ridge_cv, train_x_np, test_x_np, features)

    # Create a DataFrame for this risk and append to dfs list
    risk_df = pd.DataFrame(sorted_average_shap_values[:10], columns=['Feature', 'Average SHAP Value'])
    risk_df['Risk'] = risk  # Add a column for the risk type

    # Reorder the columns to: Risk, Feature, Average SHAP Value
    risk_df = risk_df[['Risk', 'Feature', 'Average SHAP Value']]
    risk_df['Average SHAP Value'] = risk_df['Average SHAP Value'].round(4)  # Round to four decimal places

    dfs.append(risk_df)

# After the loop, concatenate the list of DataFrames
all_results_df_regression = pd.concat(dfs, ignore_index=True)
all_results_df_regression

linear_importance

"""## overlapping percentage"""

import pandas as pd

def extract_top_for_risk(risk):
    # Extract top 10 features and importance from linear model
    top_linear = all_results_df_linear[all_results_df_linear['Risk'] == risk].nlargest(10, 'Average SHAP Value')
    linear_features = top_linear['Feature'].tolist()
    linear_importance = top_linear['Average SHAP Value'].tolist()

    # Decide the best model based on the presence of risk in all_results_df_regression
    if risk in all_results_df_regression['Risk'].values:
        top_best_model = all_results_df_regression[all_results_df_regression['Risk'] == risk].nlargest(10, 'Average SHAP Value')
        model_importance_column = 'Average SHAP Value'
    elif risk in all_results_df_DL['Risk'].values:
        top_best_model = all_results_df_DL[all_results_df_DL['Risk'] == risk].nlargest(10, 'Average SHAP Value')
        model_importance_column = 'Average SHAP Value'
    else:
        top_best_model = all_results_df_combined[all_results_df_combined['Risk'] == risk].nlargest(10, 'Average SHAP Value')
        model_importance_column = 'Average SHAP Value'

    best_model_features = top_best_model['Feature'].tolist()
    best_model_importance = top_best_model[model_importance_column].tolist()

    # Calculate percentage overlap
    overlap = len(set(linear_features).intersection(set(best_model_features))) / 10.0

    return {
        'Ranking No.': list(range(1, 11)),
        'Best model': best_model_features,
        'SHAP Value': best_model_importance,
        'Linear regression': linear_features,
        'SHAP Value_linear': linear_importance,
        'Percentage of overlap': [overlap] + [''] * 9  # Just first row contains overlap, others are empty
    }

# Extract data for each risk
risks = all_results_df_linear['Risk'].unique()
all_data = {}

for risk in risks:
    all_data[risk] = extract_top_for_risk(risk)

all_data_df = pd.concat({k: pd.DataFrame(v).T for k, v in all_data.items()}, axis=0)
all_data_df.index = all_data_df.index.set_levels([idx.capitalize() for idx in all_data_df.index.levels[0]], level=0)
all_data_df

"""## frequency count of overall risk elements"""

# Extract the rows for "Best model"
best_models = all_data_df.xs('Best model', level=1, axis=0)

# Flatten the rows and count the frequency of each element
element_frequency = best_models.stack().value_counts()

pd.DataFrame(element_frequency[:10]).T

all_data_df.to_csv('119.csv')

"""# Risk contribution"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# weight_FTA=0.6; weight_criteria=0.4
# !pip install shap
# !pip install tqdm
# threshold=0.5
# file_paths = [
#     # data simulation
#     '/content/drive/MyDrive/Paper 3/python_scripts/dataset.py',
# 
#     # functions and models
#     '/content/drive/MyDrive/Paper 3/python_scripts/functions.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/different_dl_models.py',
# 
#     # labeling
#     '/content/drive/MyDrive/Paper 3/python_scripts/fault tree.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/criteria and integration.py',
#     #'/content/drive/MyDrive/Paper 3/python_scripts/labeling integration analysis.py',
#     # '/content/drive/MyDrive/Paper 3/python_scripts/experiment with criteria threshold and FTA weights.py',
#     ]
# 
# for file_path in file_paths:
#     with open(file_path) as file:
#         exec(file.read())

new_sample_values = [0, 4, 2, 4, 5, 3, 1, 1, 2, 4, 5, 5, 5, 5, 5, 5, 1, 3, 7, 7, 7, 7, 7, 7, 0, 4, 2, 0, 4, 4, 1, 2, 2, 1, 5, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1]
df_copy = df.copy()
new_sample = pd.Series(new_sample_values, index=df_copy.columns).to_frame().T
df_copy = pd.concat([df_copy, new_sample], ignore_index=True)
df_str_copy = df_copy.astype(str)
df_one_hot_copy = pd.get_dummies(df_str_copy)
sample_df = df_one_hot_copy.iloc[-1:] # Get only the last added sample
test_sample_tensor = torch.tensor(sample_df.values.astype(int).squeeze(), dtype=torch.float)

df_one_hot['p_ransomware_label']=round((weight_FTA*df_p['p_ransomware_FTA']+weight_criteria*df_p['p_ransomware_criteria']),3)
df_one_hot['p_phishing_label']=round((weight_FTA*df_p['p_phishing_FTA']+weight_criteria*df_p['p_phishing_criteria']),3)
df_one_hot['p_insider_label']=round((weight_FTA*df_p['p_insider_FTA']+weight_criteria*df_p['p_insider_criteria']),3)
df_one_hot['p_data_label']=round((weight_FTA*df_p['p_data_FTA']+weight_criteria*df_p['p_data_criteria']),3)
df_one_hot['p_supply_label']=round((weight_FTA*df_p['p_supply_FTA']+weight_criteria*df_p['p_supply_criteria']),3)

"""## for neural network"""

# Assuming you've already defined necessary modules, functions, and initial data above

risks = ['ransomware', 'phishing']
risks = ['ransomware']
results = {}

for risk in risks:
    set_seed(0)
    label = f'p_{risk}_label'

    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :259].values)
    train_y = torch.Tensor(train_df[label].values).view(-1, 1)
    val_x = torch.Tensor(val_df.iloc[:, :259].values)
    val_y = torch.Tensor(val_df[label].values).view(-1, 1)
    test_x = torch.Tensor(test_df.iloc[:, :259].values)
    test_y = torch.Tensor(test_df[label].values).view(-1, 1)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = NeuralNetwork2()
    num_epochs = 200
    lr = 0.004
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)

    # Save the trained model's state_dict
    model_save_path = f"{risk}_model_entire.pth"
    torch.save(model, model_save_path)
    print(f"Entire model for risk '{risk}' saved at: {model_save_path}")

    model.eval()
    with torch.no_grad():
        prediction = model(test_sample_tensor.to(device)) # Using the tensor of the first sample directly
        prediction_value = round(prediction.item(), 2)

    # Construct a DataFrame for the current risk and store it in the results dictionary
    predictions_df = pd.DataFrame({
        'Risk': [risk],
        'Weight Pair': [(weight_FTA, weight_criteria)],
        'Sample 1 Predictions': [prediction_value]
    })

    results[risk] = predictions_df

# Convert the results dictionary to a dataframe
df_DL = pd.concat(results, names=['Risk', 'Row Index'])

# Display the dataframe
df_DL

new_sample=test_sample_tensor.unsqueeze(0)

# Calculate SHAP values for the new sample
explainer = shap.DeepExplainer(model, train_x.to(device))
features=df_one_hot.columns[:259]
shap_values = explainer.shap_values(new_sample)

# Initialize JavaScript for SHAP plots
shap.initjs()

# Convert new_sample to a numpy array
new_sample_np = new_sample.detach().numpy()

# Create a force plot that shows the contribution of each feature to the prediction
shap.force_plot(explainer.expected_value[0], shap_values[0].T, new_sample_np, feature_names=features)

original_features={}
for i in features:
  original_feature=i[:-2]
  if original_feature in original_features: original_features[original_feature]+=1
  else: original_features[original_feature]=1

# Function to group values according to the sum_pattern
def group_values_by_pattern(values, pattern):
    grouped_values = []
    current_index = 0
    for group_size in pattern:
        if current_index + group_size <= len(values):
            grouped_values.append(values[current_index:current_index+group_size])
            current_index += group_size
    return grouped_values

# Group the new list of values according to the sum_pattern
grouped_values = group_values_by_pattern(shap_values[0].squeeze(), original_features.values())

group_shap=[]
for group in grouped_values:
  group_shap.append(np.sum(group).round(4))

import matplotlib.pyplot as plt

# Define ten Morandi colors from darkest to lightest
morandi_colors = ['#29211F', '#5A4743', '#8D7960', '#AD9B83', '#DCCBAA', '#FEE4C4', '#FFE8AF', '#F7F1E3', '#FEF3D1', '#FFF8E1']

# Convert SHAP values to a numpy array (if they aren't already)
shap_values_np = np.array(group_shap)

# Get indices of the top ten positive SHAP values
top_ten_indices = shap_values_np.argsort()[-10:][::-1]

# Extract the corresponding feature names for these indices
top_ten_features = [list(original_features.keys())[i] for i in top_ten_indices]  # Remove the last two characters from each feature name
top_ten_values = shap_values_np[top_ten_indices]

# Creating a DataFrame:
df_fca = pd.DataFrame({'Risk factor': top_ten_features, 'Risk contribution': top_ten_values.round(4)})

# Plotting:
plt.figure(figsize=(12, 8))
bars = plt.bar(df_fca['Risk factor'], df_fca['Risk contribution'], color=morandi_colors)
plt.ylabel('Risk contribution')
base_value = str(round(explainer.expected_value[0], 2))
plt.title(f'Top 10 risk factors with their risk contributions for {risks[0]} (predicted risk degree: {prediction_value}, base value: {base_value})')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility
plt.xlabel('Risk factor')  # Add x-axis label
plt.ylim(0, 0.0210)  # Set the y-axis range

# Add value labels on top of each bar
for bar, value in zip(bars, df_fca['Risk contribution']):
    plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""## for combined model"""

risks = ['data']

risk_index_map = {
    'ransomware': 0,
    'phishing': 1,
    'insider': 2,
    'data': 3,
    'supply': 4
}

results = {}

for risk in risks:
    set_seed(0)
    label = f'p_{risk}_label'

    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :-5].values)
    train_y = torch.Tensor(train_df.iloc[:, -5:].values)
    val_x = torch.Tensor(val_df.iloc[:, :-5].values)
    val_y = torch.Tensor(val_df.iloc[:, -5:].values)
    test_x = torch.Tensor(test_df.iloc[:, :-5].values)
    test_y = torch.Tensor(test_df.iloc[:, -5:].values)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = Combined3()
    num_epochs = 200
    lr = 0.004
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_combined_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)

    # Save the trained model's state_dict
    model_save_path = f"{risk}_model_entire.pth"
    torch.save(model, model_save_path)
    print(f"Entire model for risk '{risk}' saved at: {model_save_path}")

    model.eval()
    prediction_index = risk_index_map[risk]
    with torch.no_grad():
        test_sample = test_sample_tensor
        prediction = model(test_sample.to(device))[prediction_index]
        predictions_sample_1 = round(prediction.item(), 2)

    # Construct a DataFrame for the current risk and store it in the results dictionary
    predictions_df = pd.DataFrame({
        'Weight': [weight_FTA],
        'Sample 1 Predictions': [predictions_sample_1]
    })

    results[risk] = predictions_df

# Convert the results dictionary to a dataframe
df_combined = pd.concat(results, names=['Risk', 'Row Index'])

# Display the dataframe
df_combined

class Combined3FourthOutput(nn.Module):
    def __init__(self, original_model,risk):
        super(Combined3FourthOutput, self).__init__()

        self.original_model = original_model
        self.risk=risk

    def forward(self, x):
        output = self.original_model(x)
        if self.risk=='ransomware': index=0
        elif self.risk=='phishing': index=1
        elif self.risk=='insider': index=2
        elif self.risk=='data': index=3
        else: index=4
        return output[:, index].unsqueeze(1)  # Get only the fourth output

new_model = Combined3FourthOutput(model, risks[0])

new_sample=test_sample_tensor.unsqueeze(0)

# Calculate SHAP values for the new sample
explainer = shap.DeepExplainer(new_model, train_x.to(device))
features=df_one_hot.columns[:259]
shap_values = explainer.shap_values(new_sample)

# Initialize JavaScript for SHAP plots
shap.initjs()

# Convert new_sample to a numpy array
new_sample_np = new_sample.detach().numpy()

# Create a force plot that shows the contribution of each feature to the prediction
shap.force_plot(explainer.expected_value[0], shap_values[0].T, new_sample_np, feature_names=features)

original_features={}
for i in features:
  original_feature=i[:-2]
  if original_feature in original_features: original_features[original_feature]+=1
  else: original_features[original_feature]=1

# Function to group values according to the sum_pattern
def group_values_by_pattern(values, pattern):
    grouped_values = []
    current_index = 0
    for group_size in pattern:
        if current_index + group_size <= len(values):
            grouped_values.append(values[current_index:current_index+group_size])
            current_index += group_size
    return grouped_values

# Group the new list of values according to the sum_pattern
grouped_values = group_values_by_pattern(shap_values[0].squeeze(), original_features.values())

group_shap=[]
for group in grouped_values:
  group_shap.append(np.sum(group).round(4))

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Define ten Morandi colors from darkest to lightest
morandi_colors = ['#29211F', '#5A4743', '#8D7960', '#AD9B83', '#DCCBAA', '#FEE4C4', '#FFE8AF', '#F7F1E3', '#FEF3D1', '#FFF8E1']

# Convert SHAP values to a numpy array (if they aren't already)
shap_values_np = np.array(group_shap)

# Get indices of the top ten positive SHAP values
top_ten_indices = shap_values_np.argsort()[-10:][::-1]

# Extract the corresponding feature names for these indices
top_ten_features = [list(original_features.keys())[i] for i in top_ten_indices]  # Remove the last two characters from each feature name
top_ten_values = shap_values_np[top_ten_indices]

# print("Top ten risk factors with the highest positive contributions:")
# for feature, value in zip(top_ten_features, top_ten_values):
#    print(f"Feature: {feature}, SHAP Value: {round(value,4)}")

# Creating a DataFrame:
df_fca = pd.DataFrame({'Feature': top_ten_features, 'SHAP Value': top_ten_values.round(4)})

# Plotting:
plt.figure(figsize=(12, 8))
bars = plt.bar(df_fca['Feature'], df_fca['SHAP Value'], color=morandi_colors)
plt.ylabel('Risk contribution')
base_value = str(round(explainer.expected_value[0], 2))
plt.title(f'Top 10 risk factors with their risk contributions for data breach (predicted risk degree: {predictions_sample_1}, base value: {base_value})')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility
plt.xlabel('Risk factor')  # Add x-axis label
# plt.ylim(0, 0.0210)  # Set the y-axis range
# Add value labels on top of each bar
for bar, value in zip(bars, df_fca['SHAP Value']):
    plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""## for regression"""

# Set seed, assuming set_seed is defined somewhere else in your code
set_seed(0)
import joblib

# Set the risk and weight
risk = 'insider'
risk = 'supply'
weight_FTA = 0.6

# Set the label
label = f'p_{risk}_label'

# Split the data into training, validation, and test sets
train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1),
                                     [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])

# Create tensors for training data
train_x = torch.Tensor(train_df.iloc[:, :259].values)
train_y = torch.Tensor(train_df[label].values).view(-1, 1)

# Convert tensors to numpy arrays
train_val_x_np = train_x.numpy()
train_val_y_np = train_y.numpy().reshape(-1,)  # reshape to 1D if needed

# Initialize the Ridge model
ridge = Ridge()

# Define grid of hyperparameters 'alpha'
param_grid = {'alpha': np.logspace(-4, 4, 100)}

# Perform grid search with cross-validation
ridge_cv = GridSearchCV(ridge, param_grid, cv=5)
ridge_cv.fit(train_val_x_np, train_val_y_np)

# Print the best alpha
print("Best alpha: ", ridge_cv.best_params_)

# Save the trained Ridge model
model_save_path = f"{risk}_model_entire.pkl"
joblib.dump(ridge_cv, model_save_path)
print(f"Trained GridSearchCV (Ridge) model saved to: {model_save_path}")

# Test the first sample
test_sample = test_sample_tensor  # Make sure test_sample_tensor is defined
ridge_pred = ridge_cv.predict(test_sample.view(1,-1).numpy())
predicted_value=round(ridge_pred[0], 2)

# Create DataFrame with the results
predictions_df = pd.DataFrame({
    'Weight Pair': [(round(weight_FTA, 1), round(1 - weight_FTA, 1))],
    'Sample 1 Predictions': predicted_value,
})

print(predictions_df)

# Assuming test_sample_tensor is a PyTorch tensor
new_sample_np = test_sample_tensor.unsqueeze(0).numpy()

# Initialize SHAP explainer with Ridge CV model's predict function and training data
explainer = shap.Explainer(ridge_cv.predict, train_x.numpy())
shap_values = explainer(new_sample_np, max_evals=520)

# Assuming df_one_hot is a DataFrame with feature names
features = df_one_hot.columns[:259]  # Adjust the range as necessary for your features

# Initialize JavaScript for SHAP plots (if you're in a Jupyter Notebook)
shap.initjs()

# Create a force plot for the new sample's prediction explanation
# Draw a SHAP force plot for the first prediction
shap.plots.force(shap_values[0], feature_names=features)
# shap.force_plot(explainer.expected_value, shap_values.values[0], new_sample_np[0], feature_names=features)

import matplotlib.pyplot as plt

# Define ten Morandi colors from darkest to lightest
morandi_colors = ['#29211F', '#5A4743', '#8D7960', '#AD9B83', '#DCCBAA', '#FEE4C4', '#FFE8AF', '#F7F1E3', '#FEF3D1', '#FFF8E1']

# Convert SHAP values to a numpy array (if they aren't already)
shap_values_np = np.array(shap_values.values[0])

# Get indices of the top ten positive SHAP values
top_ten_indices = shap_values_np.argsort()[-10:][::-1]

# Extract the corresponding feature names for these indices
top_ten_features = [features[i][:-2] for i in top_ten_indices]  # Remove the last two characters from each feature name
top_ten_values = shap_values_np[top_ten_indices]

# Creating a DataFrame:
df_fca = pd.DataFrame({'Risk factor': top_ten_features, 'Risk contribution': top_ten_values.round(4)})

# Plotting:
plt.figure(figsize=(12, 8))
bars = plt.bar(df_fca['Risk factor'], df_fca['Risk contribution'], color=morandi_colors)
plt.ylabel('Risk contribution')
plt.title(f'Top 10 risk factors with their risk contributions for {risks[0]} (predicted risk degree: {prediction_value})')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility
plt.xlabel('Risk factor')  # Add x-axis label
plt.ylim(0, 0.0210)  # Set the y-axis range

# Add value labels on top of each bar
for bar, value in zip(bars, df_fca['Risk contribution']):
    plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Compute contributions for the specific instance
instance = test_sample_tensor.view(1,-1).numpy()
contributions = instance * ridge_cv.best_estimator_.coef_

# Rank the contributions
feature_names = df_one_hot.columns[:259]
sorted_indices = np.argsort(-contributions[0])  # Sort in descending order
ranked_features = feature_names[sorted_indices]
ranked_contributions = contributions[0][sorted_indices]

# Get positively contributing features and their values
positive_contributors = [(feature[:-2], round(value,4)) for feature, value in zip(ranked_features[:10], ranked_contributions[:10])]

# Convert to a DataFrame for a clearer view
positive_df = pd.DataFrame(positive_contributors, columns=['Feature', 'Contribution'])
positive_df.transpose()

# Define ten Morandi colors from darkest to lightest
morandi_colors = ['#29211F', '#5A4743', '#8D7960', '#AD9B83', '#DCCBAA', '#FEE4C4', '#FFE8AF', '#F7F1E3', '#FEF3D1', '#FFF8E1']

# Plotting:
plt.figure(figsize=(12, 6))
bars = plt.bar(positive_df['Feature'], positive_df['Contribution'], color=morandi_colors)
plt.ylabel('Risk contribution')
title= 'insider attack' if risk=='insider' else 'supply chain attack'
plt.title(f'Top 10 risk factors with their risk contributions for {title} (predicted risk degree: {str(predicted_value)[:4]})')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility
plt.xlabel('Risk factor')  # Add x-axis label
plt.ylim(0, 0.0210)  # Set the y-axis range

# Add value labels on top of each bar
for bar, value in zip(bars, positive_df['Contribution']):
    plt.text(bar.get_x() + bar.get_width() / 2, value, str(round(value,4)), ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

def plot_all_contributions(features, contributions, top_n=10):
    """
    Plots both positive and negative contributions of features.

    :param features: List of feature names
    :param contributions: Corresponding contributions of the features
    :param top_n: Number of top features to display for both positive and negative
    """
    # Partition contributions into positive and negative
    pos_contributions = [c for c in contributions if c > 0]
    neg_contributions = [c for c in contributions if c <= 0]

    pos_features = [f for f, c in zip(features, contributions) if c > 0]
    neg_features = [f for f, c in zip(features, contributions) if c <= 0]

    # Sort and select top_n for both
    pos_indices = np.argsort(-np.array(pos_contributions))
    neg_indices = np.argsort(np.array(neg_contributions))

    pos_contributions = np.array(pos_contributions)[pos_indices[:top_n]].tolist()
    neg_contributions = np.array(neg_contributions)[neg_indices[:top_n]].tolist()

    pos_features = np.array(pos_features)[pos_indices[:top_n]].tolist()
    neg_features = np.array(neg_features)[neg_indices[:top_n]].tolist()

    # Plot
    fig, ax = plt.subplots(figsize=(10, 7))

    # Positive contributions
    ax.barh(pos_features, pos_contributions, align='center', color='green', label='Positive Contributions')
    # Negative contributions
    ax.barh(neg_features, neg_contributions, align='center', color='blue', label='Negative Contributions')

    # Labels and title
    ax.set_xlabel('Contribution')
    ax.set_title('Top {} Feature Contributions (Positive and Negative)'.format(top_n))
    ax.legend()
    plt.show()

# Now call the plotting function
plot_all_contributions(positive_df['Feature'], positive_df['Contribution'], top_n=5)

"""# Risk reduction"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# weight_FTA=0.6; weight_criteria=0.4
# !pip install shap
# threshold=0.5
# file_paths = [
#     # data simulation
#     '/content/drive/MyDrive/Paper 3/python_scripts/dataset.py',
# 
#     # functions and models
#     '/content/drive/MyDrive/Paper 3/python_scripts/functions.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/different_dl_models.py',
# 
#     # labeling
#     '/content/drive/MyDrive/Paper 3/python_scripts/fault tree.py',
#     '/content/drive/MyDrive/Paper 3/python_scripts/criteria and integration.py',
#     #'/content/drive/MyDrive/Paper 3/python_scripts/labeling integration analysis.py',
#     # '/content/drive/MyDrive/Paper 3/python_scripts/experiment with criteria threshold and FTA weights.py',
#     ]
# 
# for file_path in file_paths:
#     with open(file_path) as file:
#         exec(file.read())
# 
# df_one_hot['p_ransomware_label']=round((weight_FTA*df_p['p_ransomware_FTA']+weight_criteria*df_p['p_ransomware_criteria']),3)
# df_one_hot['p_phishing_label']=round((weight_FTA*df_p['p_phishing_FTA']+weight_criteria*df_p['p_phishing_criteria']),3)
# df_one_hot['p_insider_label']=round((weight_FTA*df_p['p_insider_FTA']+weight_criteria*df_p['p_insider_criteria']),3)
# df_one_hot['p_data_label']=round((weight_FTA*df_p['p_data_FTA']+weight_criteria*df_p['p_data_criteria']),3)
# df_one_hot['p_supply_label']=round((weight_FTA*df_p['p_supply_FTA']+weight_criteria*df_p['p_supply_criteria']),3)

"""## For DL"""

# Assuming you've already defined necessary modules, functions, and initial data above
risks = ['phishing']
results = {}

for risk in risks:
    set_seed(0)
    label = f'p_{risk}_label'

    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :259].values)
    train_y = torch.Tensor(train_df[label].values).view(-1, 1)
    val_x = torch.Tensor(val_df.iloc[:, :259].values)
    val_y = torch.Tensor(val_df[label].values).view(-1, 1)
    test_x = torch.Tensor(test_df.iloc[:, :259].values)
    test_y = torch.Tensor(test_df[label].values).view(-1, 1)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = NeuralNetwork2()
    num_epochs = 200
    lr = 0.004
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, label)

import matplotlib.pyplot as plt

new_sample_values = [0, 4, 2, 4, 5, 3, 1, 1, 2, 4, 5, 5, 5, 5, 5, 5, 1, 3, 7, 7, 7, 7, 7, 7, 0, 4, 2, 0, 4, 4, 1, 2, 2, 1, 5, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1]
df_copy = df.copy()
new_sample = pd.Series(new_sample_values, index=df_copy.columns)
df_copy = df_copy.append(new_sample, ignore_index=True)
df_str_copy = df_copy.astype(str)
df_one_hot_copy = pd.get_dummies(df_str_copy)
sample_df = df_one_hot_copy.iloc[-1:] # Get only the last added sample
test_sample_tensor = torch.tensor(sample_df.values.astype(int).squeeze(), dtype=torch.float)

new_sample=test_sample_tensor.unsqueeze(0)
prediction_value_origin=round(model(test_sample_tensor.to(device)).item(),10)
print (round(prediction_value_origin,2))

explainer = shap.DeepExplainer(model, train_x.to(device))
features=df_one_hot.columns[:259]
shap_values = explainer.shap_values(new_sample)
shap_values_np = np.array(shap_values[0])

"""* Outcome: [(risk_factor, shap_value)...]"""

original_features={}
for i in features:
  original_feature=i[:-2]
  if original_feature in original_features: original_features[original_feature]+=1
  else: original_features[original_feature]=1

# Function to group values according to the sum_pattern
def group_values_by_pattern(values, pattern):
    grouped_values = []
    current_index = 0
    for group_size in pattern:
        if current_index + group_size <= len(values):
            grouped_values.append(values[current_index:current_index+group_size])
            current_index += group_size
    return grouped_values

# Group the new list of values according to the sum_pattern
grouped_values = group_values_by_pattern(shap_values_np.squeeze(), original_features.values())

group_shap=[]
for group in grouped_values:
  group_shap.append(np.sum(group).round(4))

risk_factor_shap=[]
for i,j in zip(original_features.keys(), group_shap):
  risk_factor_shap.append((i,j))
sorted_risk_factor_shap = sorted(risk_factor_shap, key=lambda x: x[1], reverse=True)

predictions_after_refinement = []
optimized_risk_factors_count = []
risk_factor_names = []

# Store the optimal values for each risk factor
optimal_values = {}

# Convert new_sample_values list to dictionary
base_sample_values = dict(zip(df.columns, new_sample_values))

for i in range(46):
    risk_factor=sorted_risk_factor_shap[i][0]
    unique_values = df_copy[risk_factor].unique()

    # Exclude certain values based on the feature name
    if risk_factor.startswith("2.2") and 5 in unique_values:
        unique_values = [x for x in unique_values if x != 5]
    if risk_factor.startswith("2.3") and 7 in unique_values:
        unique_values = [x for x in unique_values if x != 7]

    # Initiate values for comparison
    min_prediction_value = float('inf')
    optimal_feature_value = None

    # Loop through all unique values
    for value in unique_values:
        current_sample = base_sample_values.copy()
        current_sample[risk_factor] = value
        new_sample = pd.Series(current_sample)
        df_temp = pd.concat([df, new_sample.to_frame().T], ignore_index=True)
        df_str_temp = df_temp.astype(str)
        df_one_hot_temp = pd.get_dummies(df_str_temp)
        sample_df = df_one_hot_temp.iloc[-1:]
        test_sample_tensor = torch.tensor(sample_df.values.astype(int).squeeze(), dtype=torch.float)

        model.eval()
        with torch.no_grad():
            prediction = model(test_sample_tensor.to(device))
            prediction_value = prediction.item()

        if prediction_value < min_prediction_value:
            min_prediction_value = prediction_value
            optimal_feature_value = value

    # Store the optimal value for this feature
    optimal_values[risk_factor] = optimal_feature_value

    # Update base_sample_values with the optimal value for that feature
    base_sample_values[risk_factor] = optimal_values[risk_factor]

    risk_factor_names.append(f"{risk_factor}={optimal_values[risk_factor]}")

    # Now create a sample using the optimal values and predict
    final_sample_values = base_sample_values.copy()
    for feature, value in optimal_values.items():
        final_sample_values[feature] = value

    final_sample = pd.Series(final_sample_values)
    df_final = pd.concat([df, final_sample.to_frame().T], ignore_index=True)
    df_str_final = df_final.astype(str)
    df_one_hot_final = pd.get_dummies(df_str_final)
    sample_df_final = df_one_hot_final.iloc[-1:]
    test_sample_tensor_final = torch.tensor(sample_df_final.values.astype(int).squeeze(), dtype=torch.float)

    model.eval()
    with torch.no_grad():
        final_prediction = model(test_sample_tensor_final.to(device))
        final_prediction_value = final_prediction.item()

    predictions_after_refinement.append(final_prediction_value)
    optimized_risk_factors_count.append(len(optimal_values))
predictions_after_refinement.insert(0,prediction_value_origin)
risk_factor_names.insert(0,'Original')
print('-'*10)
print(f"Optimal values for risk factors are: {optimal_values}")
print(f"Prediction from the final combination of optimal values is: {final_prediction_value}")

plt.figure(figsize=(8, 5))

# Find max and min prediction values
max_pred = max(predictions_after_refinement)
min_pred = min(predictions_after_refinement)

# Identify the index for the first prediction below 0.5
first_below_half_idx = next(i for i, pred in enumerate(predictions_after_refinement) if pred < 0.5)

for i, (pred, risk_factor) in enumerate(zip(predictions_after_refinement, risk_factor_names)):
    if pred == max_pred:
        plt.plot(i, pred, '^', markersize=12, label=f"Original: {pred:.2f}")
    elif pred == min_pred:
        plt.plot(i, pred, 'v', markersize=12, label=f"Min (x={i}): {pred:.3f}")
    elif i == first_below_half_idx:
        plt.plot(i, pred, '*', markersize=12, label=f"First<0.5 (x={i}): {pred:.3f}")
    else:
        plt.plot(i, pred, 'o')
    if 1<=i<=3:
        plt.annotate('Risk factor '+risk_factor[:-2], (i, pred), textcoords="offset points", xytext=(8,-2))
    if pred == min_pred:
        plt.annotate('Risk factor '+risk_factor[:-2], (i, pred), textcoords="offset points", xytext=(10,12), ha='center')
    if i==0:
        plt.annotate('Original prediction', (i, pred), textcoords="offset points", xytext=(8,-5))

plt.xlabel('Number of Risk Factors Optimized')
plt.ylabel('Prediction Value After Optimization')
plt.title('Optimized Risk Factors and Their Effects on Predictions for Phishing')

# Add a horizontal dotted line at y=0.5
plt.axhline(y=0.5, color='gray', linestyle='--')

plt.legend(loc='upper right', ncol=1)
plt.tight_layout()
plt.show()

import pandas as pd

risk_factor_names=risk_factor_names[1:]
predictions_after_refinement=predictions_after_refinement[1:]

# Extract feature names from the risk_factor_names
feature_names = [name.split('=')[0] for name in risk_factor_names]

# Retrieve optimal values corresponding to the feature names
optimal_values_for_features = [optimal_values[feature] for feature in feature_names]

# Create the DataFrame
df_table = pd.DataFrame({
    'Feature Names': feature_names,
    'Optimal Values': optimal_values_for_features,
    'Predictions': [round(pred, 3) for pred in predictions_after_refinement]
})

# Transpose to get the desired format
df_table1 = df_table.transpose()
df_table1

"""## For combined model"""

risks = ['data']

risk_index_map = {
    'ransomware': 0,
    'phishing': 1,
    'insider': 2,
    'data': 3,
    'supply': 4
}

results = {}

for risk in risks:
    set_seed(0)
    label = f'p_{risk}_label'

    train_df, val_df, test_df = np.split(df_one_hot.sample(frac=1), [int(.7*len(df_one_hot)), int(.9*len(df_one_hot))])
    train_x = torch.Tensor(train_df.iloc[:, :-5].values)
    train_y = torch.Tensor(train_df.iloc[:, -5:].values)
    val_x = torch.Tensor(val_df.iloc[:, :-5].values)
    val_y = torch.Tensor(val_df.iloc[:, -5:].values)
    test_x = torch.Tensor(test_df.iloc[:, :-5].values)
    test_y = torch.Tensor(test_df.iloc[:, -5:].values)

    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_dataset = TensorDataset(val_x, val_y)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_dataset = TensorDataset(test_x, test_y)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = Combined3()
    num_epochs = 200
    lr = 0.004
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    model, val_losses, best_epoch, min_val_loss = train_combined_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)

import matplotlib.pyplot as plt

new_sample_values = [0, 4, 2, 4, 5, 3, 1, 1, 2, 4, 5, 5, 5, 5, 5, 5, 1, 3, 7, 7, 7, 7, 7, 7, 0, 4, 2, 0, 4, 4, 1, 2, 2, 1, 5, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1]
df_copy = df.copy()
new_sample = pd.Series(new_sample_values, index=df_copy.columns)
df_copy = df_copy.append(new_sample, ignore_index=True)
df_str_copy = df_copy.astype(str)
df_one_hot_copy = pd.get_dummies(df_str_copy)
sample_df = df_one_hot_copy.iloc[-1:] # Get only the last added sample
test_sample_tensor = torch.tensor(sample_df.values.astype(int).squeeze(), dtype=torch.float)

new_sample=test_sample_tensor.unsqueeze(0)
prediction_value_origin=round(model(test_sample_tensor.to(device)).squeeze()[risk_index_map[risks[0]]].item(), 2)
print(round(model(test_sample_tensor.to(device)).squeeze()[risk_index_map[risks[0]]].item(), 2))

# Define the new model class
class RiskSpecificOutput(nn.Module):
    def __init__(self, original_model, risk):
        super(RiskSpecificOutput, self).__init__()
        self.original_model = original_model
        self.risk_to_index = {
            'ransomware': 0,
            'phishing': 1,
            'insider': 2,
            'data': 3
        }
        self.index = self.risk_to_index.get(risk, 4)  # Default to index 4 if risk not found

    def forward(self, x):
        output = self.original_model(x)
        return output[:, self.index].unsqueeze(1)  # Get the output for the specified risk

# Create an instance of the new model
new_model = RiskSpecificOutput(model, risks[0])

new_sample = test_sample_tensor.unsqueeze(0)

# Calculate SHAP values for the new sample
explainer = shap.DeepExplainer(new_model, train_x.to(device))
features = df_one_hot.columns[:259]
shap_values = explainer.shap_values(new_sample)

# Convert new_sample to a numpy array
new_sample_np = new_sample.detach().numpy()

# Convert SHAP values to a numpy array (if they aren't already)
shap_values_np = np.array(shap_values[0])

original_features={}
for i in features:
  original_feature=i[:-2]
  if original_feature in original_features: original_features[original_feature]+=1
  else: original_features[original_feature]=1

# Function to group values according to the sum_pattern
def group_values_by_pattern(values, pattern):
    grouped_values = []
    current_index = 0
    for group_size in pattern:
        if current_index + group_size <= len(values):
            grouped_values.append(values[current_index:current_index+group_size])
            current_index += group_size
    return grouped_values

# Group the new list of values according to the sum_pattern
grouped_values = group_values_by_pattern(shap_values_np.squeeze(), original_features.values())

group_shap=[]
for group in grouped_values:
  group_shap.append(np.sum(group).round(4))

risk_factor_shap=[]
for i,j in zip(original_features.keys(), group_shap):
  risk_factor_shap.append((i,j))
sorted_risk_factor_shap = sorted(risk_factor_shap, key=lambda x: x[1], reverse=True)

predictions_after_refinement = []
optimized_risk_factors_count = []
risk_factor_names = []
optimal_values = {}

# Convert new_sample_values list to dictionary
base_sample_values = dict(zip(df.columns, new_sample_values))

for i in range(46):

    risk_factor=sorted_risk_factor_shap[i][0]
    unique_values = df_copy[risk_factor].unique()

    # Exclude certain values based on the feature name
    if risk_factor.startswith("2.2") and 5 in unique_values:
        unique_values = [x for x in unique_values if x != 5]

    if risk_factor.startswith("2.3") and 7 in unique_values:
        unique_values = [x for x in unique_values if x != 7]

    min_prediction_value = float('inf')
    optimal_feature_value = None

    for value in unique_values:
        current_sample = base_sample_values.copy()
        current_sample[risk_factor] = value
        new_sample = pd.Series(current_sample)
        df_temp = pd.concat([df, new_sample.to_frame().T], ignore_index=True)
        df_str_temp = df_temp.astype(str)
        df_one_hot_temp = pd.get_dummies(df_str_temp)
        sample_df = df_one_hot_temp.iloc[-1:]
        test_sample_tensor = torch.tensor(sample_df.values.astype(int).squeeze(), dtype=torch.float)

        model.eval()
        with torch.no_grad():
            prediction = model(test_sample_tensor.to(device)).squeeze()[risk_index_map[risks[0]]]
            prediction_value = prediction.item()

        if prediction_value < min_prediction_value:
            min_prediction_value = prediction_value
            optimal_feature_value = value

    optimal_values[risk_factor] = optimal_feature_value
    base_sample_values[risk_factor] = optimal_values[risk_factor]
    risk_factor_names.append(f"{risk_factor}={optimal_values[risk_factor]}")

    final_sample_values = base_sample_values.copy()
    for feature, value in optimal_values.items():
        final_sample_values[feature] = value

    final_sample = pd.Series(final_sample_values)
    df_final = pd.concat([df, final_sample.to_frame().T], ignore_index=True)
    df_str_final = df_final.astype(str)
    df_one_hot_final = pd.get_dummies(df_str_final)
    sample_df_final = df_one_hot_final.iloc[-1:]
    test_sample_tensor_final = torch.tensor(sample_df_final.values.astype(int).squeeze(), dtype=torch.float)

    model.eval()
    with torch.no_grad():
        final_prediction = model(test_sample_tensor_final.to(device)).squeeze()[risk_index_map[risks[0]]]
        final_prediction_value = final_prediction.item()

    predictions_after_refinement.append(final_prediction_value)
    optimized_risk_factors_count.append(len(optimal_values))
predictions_after_refinement.insert(0,prediction_value_origin)
risk_factor_names.insert(0,'Original')
print('-'*10)
print(len(optimal_values))
print(f"Optimal values for risk factors are: {optimal_values}")
print(f"Prediction from the final combination of optimal values is: {final_prediction_value}")

plt.figure(figsize=(8, 5))

# Find max and min prediction values
max_pred = max(predictions_after_refinement)
min_pred = min(predictions_after_refinement)

# Identify the index for the first prediction below 0.5
first_below_half_idx = next(i for i, pred in enumerate(predictions_after_refinement) if pred < 0.5)

for i, (pred, risk_factor) in enumerate(zip(predictions_after_refinement, risk_factor_names)):
    if pred == max_pred:
        plt.plot(i, pred, '^', markersize=12, label=f"Original: {pred:.2f}")
    elif pred == min_pred:
        plt.plot(i, pred, 'v', markersize=12, label=f"Min (x={i}): {pred:.3f}")
    elif i == first_below_half_idx:
        plt.plot(i, pred, '*', markersize=12, label=f"First<0.5 (x={i}): {pred:.3f}")
    else:
        plt.plot(i, pred, 'o')
    if 1<=i<= 3:
        plt.annotate('Risk factor '+risk_factor[:-2], (i, pred), textcoords="offset points", xytext=(8,-2))
    if pred == min_pred:
        plt.annotate('Risk factor '+risk_factor[:-2], (i, pred), textcoords="offset points", xytext=(10,20), ha='center')
    if i==0:
        plt.annotate('Original prediction', (i, pred), textcoords="offset points", xytext=(8,-5))
plt.xlabel('Number of Risk Factors Optimized')
plt.ylabel('Prediction Value After Optimization')
plt.title('Optimized Risk Factors and Their Effects on Predictions for Data Breach')

# Add a horizontal dotted line at y=0.5
plt.axhline(y=0.5, color='gray', linestyle='--')

plt.legend(loc='upper right', ncol=1)
plt.tight_layout()
plt.show()

import pandas as pd

risk_factor_names=risk_factor_names[1:]
predictions_after_refinement=predictions_after_refinement[1:]

# Extract feature names from the risk_factor_names
feature_names = [name.split('=')[0] for name in risk_factor_names]

# Retrieve optimal values corresponding to the feature names
optimal_values_for_features = [optimal_values[feature] for feature in feature_names]

# Create the DataFrame
df_table = pd.DataFrame({
    'Feature Names': feature_names,
    'Optimal Values': optimal_values_for_features,
    'Predictions': [round(pred, 3) for pred in predictions_after_refinement]
})

# Transpose to get the desired format
df_table2 = df_table.transpose()

df_table2

def modify_optimal_values(row):
    if row['Feature Names'].startswith('2.2') and row['Optimal Values'] == 5:
        row['Optimal Values'] = 0
    elif row['Feature Names'].startswith('2.3') and row['Optimal Values'] == 7:
        row['Optimal Values'] = 0
    return row

# Applying the condition to concatenated_df
table_1 = df_table1.apply(modify_optimal_values, axis=0)
table_2 = df_table2.apply(modify_optimal_values, axis=0)
concatenated_df = pd.concat([table_1, table_2], axis=0)
concatenated_df.to_csv('111.csv')

"""# Model probing"""

# Transforming the provided data into lists
ransomware_R2 = [0.998, 0.999, 0.999, 0.999, 0.998, 0.998, 0.998, 0.998, 0.996, 0.997, 0.998, 0.999, 0.998]
phishing_R2= [0.996, 0.997, 0.995, 0.996, 0.995, 0.996, 0.992, 0.993, 0.992, 0.993, 0.996, 0.996, 0.996]
insider_R2= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.999, 0.999, 0.999]
data_R2= [0.995, 0.994, 0.995, 0.995, 0.992, 0.995, 0.992, 0.992, 0.99, 0.989, 0.994, 0.995, 0.996]
supply_R2= [0.998, 0.998, 0.999, 0.999, 0.999, 0.998, 1, 1, 0.997, 0.997, 0.999, 0.998, 0.998]
models = ["NN_1", "NN_2", "NN_3", "NN_4", "NN_5", "NN_6", "Linear", "Ridge", "Lasso", "Polynomial", "Combined_NN_1", "Combined_NN_2", "Combined_NN_3"]

import matplotlib.pyplot as plt

# Define even darker Morandi colors for each risk type
even_darker_morandi_colors = ['#704B75', '#8B5A4A', '#727F8D', '#5F7469', '#C9B545']

plt.figure(figsize=(10, 7))

# Plotting the R² values for each risk type with even darker Morandi colors
plt.plot(models, ransomware_R2, marker='o', label='Ransomware', linestyle='--', color=even_darker_morandi_colors[0])
plt.plot(models, phishing_R2, marker='o', label='Phishing', linestyle='--', color=even_darker_morandi_colors[1])
plt.plot(models, insider_R2, marker='o', label='Insider attack', linestyle='--', color=even_darker_morandi_colors[2])
plt.plot(models, data_R2, marker='o', label='Data breach', linestyle='--', color=even_darker_morandi_colors[3])
plt.plot(models, supply_R2, marker='o', label='Supply chain attack', linestyle='--', color=even_darker_morandi_colors[4])

# Setting labels, title, and legend
plt.xlabel('Models')
plt.ylabel('R² Value')
plt.title('R² Values Across Different Models for Each Risk Type')
plt.xticks(rotation=45)
plt.legend()

# Remove the grid
plt.grid(False)

plt.tight_layout()
plt.show()

ransomware_metrics=[2.02E-05, 4.50E-03, 3.43E-03, 0.998]
phishing_metrics=[1.27E-04, 1.13E-02, 9.12E-03, 0.992]
insider_metrics=[2.14E-06, 1.46E-03, 1.09E-03, 1]
data_metrics=[7.96E-05, 8.92E-03, 6.89E-03, 0.992]
supply_metrics=[9.92E-07, 9.96E-04, 7.59E-04, 1]
metrics=['MSE','RMSE','MAE','R²']

import matplotlib.pyplot as plt

# Define darker Morandi colors
darker_morandi_colors = ['#8E6B98', '#C4947B', '#9BA7AF', '#88A198', '#E9D279']

fig, axs = plt.subplots(2, 2, figsize=(15, 10))

# Plotting MSE
axs[0, 0].bar(['Ransomware', 'Phishing', 'Insider', 'Data', 'Supply'],
              [ransomware_metrics[0], phishing_metrics[0], insider_metrics[0], data_metrics[0], supply_metrics[0]],
              color=darker_morandi_colors)
axs[0, 0].set_title('MSE')
axs[0, 0].set_ylabel('Value')

# Plotting RMSE
axs[0, 1].bar(['Ransomware', 'Phishing', 'Insider', 'Data', 'Supply'],
              [ransomware_metrics[1], phishing_metrics[1], insider_metrics[1], data_metrics[1], supply_metrics[1]],
              color=darker_morandi_colors)
axs[0, 1].set_title('RMSE')

# Plotting MAE
axs[1, 0].bar(['Ransomware', 'Phishing', 'Insider', 'Data', 'Supply'],
              [ransomware_metrics[2], phishing_metrics[2], insider_metrics[2], data_metrics[2], supply_metrics[2]],
              color=darker_morandi_colors)
axs[1, 0].set_title('MAE')
axs[1, 0].set_ylabel('Value')

# Plotting R² with adjusted y-axis range
axs[1, 1].bar(['Ransomware', 'Phishing', 'Insider', 'Data', 'Supply'],
              [ransomware_metrics[3], phishing_metrics[3], insider_metrics[3], data_metrics[3], supply_metrics[3]],
              color=darker_morandi_colors)
axs[1, 1].set_title('R²')
axs[1, 1].set_ylim(0.99, 1)

plt.tight_layout()
plt.show()

